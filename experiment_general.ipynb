{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf911ebc-774f-49cb-aaeb-d5f00fe76bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers==4.43.1\n",
    "# pip install torch=2.0.0\n",
    "# pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2281e2e0-b171-426a-b4fd-92481417f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" # For running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3795bd3-27cb-4ec9-bec3-086249e7ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig\n",
    ")\n",
    "from transformers.models.llama.modeling_llama import LlamaRotaryEmbedding\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f564bd-ca13-479e-bed1-b19611b1b482",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1cda52-d419-41db-8a97-38a7a58003df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN_READ = \"xxx\" # Replace with HF access token\n",
    "cache_dir = 'xxx' # Replace with desired cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8629d3-2ca8-48e7-90ea-f50dd07c398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/transformers_latest/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:785: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, padding_side=\"left\", cache_dir=cache_dir, use_auth_token=ACCESS_TOKEN_READ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d3b5b-d8ff-4177-b5ac-7ab50ddf3f12",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1922b8-c460-49cb-b000-1b3041f55515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44972, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National Archives \\n \\n Yes, it’s that time ag...</td>\n",
       "      <td>– The unemployment rate dropped to 8.2% last m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOS ANGELES (AP) — In her first interview sinc...</td>\n",
       "      <td>– Shelly Sterling plans \"eventually\" to divorc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GAITHERSBURG, Md. (AP) — A small, private jet ...</td>\n",
       "      <td>– A twin-engine Embraer jet that the FAA descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tucker Carlson Exposes His Own Sexism on Twitt...</td>\n",
       "      <td>– Tucker Carlson is in deep doodoo with conser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man accused of removing another man's testic...</td>\n",
       "      <td>– What are the three most horrifying words in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  National Archives \\n \\n Yes, it’s that time ag...   \n",
       "1  LOS ANGELES (AP) — In her first interview sinc...   \n",
       "2  GAITHERSBURG, Md. (AP) — A small, private jet ...   \n",
       "3  Tucker Carlson Exposes His Own Sexism on Twitt...   \n",
       "4  A man accused of removing another man's testic...   \n",
       "\n",
       "                                             summary  \n",
       "0  – The unemployment rate dropped to 8.2% last m...  \n",
       "1  – Shelly Sterling plans \"eventually\" to divorc...  \n",
       "2  – A twin-engine Embraer jet that the FAA descr...  \n",
       "3  – Tucker Carlson is in deep doodoo with conser...  \n",
       "4  – What are the three most horrifying words in ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data as DataFrame\n",
    "ds = load_dataset(\"therapara/summary-of-news-articles\", cache_dir=cache_dir)\n",
    "df = pd.DataFrame(ds['train'])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "43e85d97-f42f-4760-8870-fc6048c90066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17693231343947344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/transformers_latest/lib/python3.11/site-packages/seaborn/categorical.py:700: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n",
      "  artists = ax.bxp(**boxplot_kws)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (checking if dataset has more than 4096 for testing on llama2)\n",
    "tqdm.pandas()\n",
    "df['token_length'] = df['document'].progress_apply(lambda x: len(tokenizer(x)['input_ids']))\n",
    "\n",
    "print(sum(df['token_length'] > 4096) / len(df))\n",
    "\n",
    "plt.figure(figsize=(15, 1))\n",
    "boxprops = dict(linewidth=2, color='coral')\n",
    "flierprops = dict(marker='.', markerfacecolor='darkseagreen', markersize=8, markeredgecolor='none')\n",
    "sns.boxplot(x=df['token_length'], boxprops=boxprops, flierprops=flierprops)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d2db4bb-79ce-494d-881e-3a15b8c214fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose example with > 10000 token length for testing\n",
    "x = 294\n",
    "example = df.iloc[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c181d5d9-f8c9-4069-9f49-6c0e95126ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token length: 12588\n",
      "\n",
      "==== Snippet of full document =====\n",
      " A host of hardy microbes may be living miles beneath the ocean floor, new research suggests. \n",
      " \n",
      " Complex chemical compounds found in the rocks spewed from oceanic mud volcanoes suggest microbial life-forms may be dwelling some 32,800 feet (10,000 meters) beneath the seafloor. Though scientists have not yet found a smoking gun proving that life exists in these subterranean depths, similar chemical compounds have been found in other places where hardy microbes cling to life. \n",
      " \n",
      " \"Although we canno\n",
      "\n",
      "==== Summary =====\n",
      " – A team of researchers may have discovered evidence of the deepest life on Earth (and we're not talking college freshmen taking their first philosophy class). According to a study published Monday in Proceedings of the National Academy of Sciences, there may be microbes living up to six miles under the seafloor. Researchers used a remotely operated vehicle to retrieve 46 samples of a rock called serpentine from a mud volcano near the Mariana Trench—the deepest place on Earth—southwest of Japan, Phys.org reports. According to Live Science, the serpentine may have originated more than 12 miles under the seafloor before being spewed out by the mud volcano. While the serpentine didn't contain any actual microbes, researchers did find what National Geographic calls \"tantalizing traces of organic material.\" Due to the particulars of the subduction zone at the Mariana Trench, the researchers believe the microbes could have survived up to six miles below the seafloor before the pressure and heat became too much. They believe the organisms could survive on the methane and hydrogen produced when serpentine forms. \"This is another hint at a great, deep biosphere on our planet,\" study lead Oliver Plümper says. (Near the ocean's deepest spot, scientists heard a 3.5-second symphony.)\n"
     ]
    }
   ],
   "source": [
    "print(\"Token length:\", example['token_length'])\n",
    "print(\"\\n==== Snippet of full document =====\\n\", example['document'][:500])\n",
    "print(\"\\n==== Summary =====\\n\", example['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df672ed-d37d-4852-b981-ec049472de0d",
   "metadata": {},
   "source": [
    "## Run model without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac781ca-fee0-42dd-9f36-8da6ade9d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "def infer(model, text, max_new_tokens=300):\n",
    "    sentence = f\"Read this document: {text} \\nSummarise it in one sentence:\"\n",
    "    \n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to('cuda')\n",
    "    print('Sentence token length:', len(inputs['attention_mask'][0]))\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    decoded_answer = decoded_outputs.replace(sentence, '')\n",
    "\n",
    "    # This frees up gpu memory after each call\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    time.sleep(1)\n",
    "\n",
    "    return decoded_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b222db-19e0-4e8e-9e17-3fb9f744ef87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e59e466b5548ee8895927fd3f219ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    cache_dir=cache_dir, \n",
    "    device_map='auto',\n",
    "    token=ACCESS_TOKEN_READ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87463c3e-ea19-4cb8-89e2-11eb2d70511a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e4d9a09-28ec-49f9-81de-8392b63096e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.max_position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97354e80-5e04-415f-929a-8711493568d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence token length: 12602\n",
      "CPU times: user 28.2 s, sys: 5.39 s, total: 33.6 s\n",
      "Wall time: 37.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'պЉЋ\\nƏՄ.../ inЋЏՀЉЉЁգЋЪհЉЋЉЪՄհգЋշЁЏЩЉЉЉЉЉղՍգЏЏЉշЉЁզЉЉЪ\\nЏՍպգ...ЉպհЏ C-Ћ.ЋգЉЩЋƏЪЋЏЉЪհЪƏ. ,ЋЪՍ PЋЁЉЪ..ղЉЪЉЋЉ. CЏЉЉЋ\\nՍЋЋ.ЁЋզЉЪЋգ...\\nЪnЋՄЉЉЪ...Ъ- PЋЋЉЪհЩЉՄզЋЉЏЋЋ ЉշЪքЉЏЉЪЉЉЉԱЪЉ CЉբշЉЏգЉЉЉЏҚՀՄЉЏƏЉքҚЉЪЋЉգЏЋЉ ЉղЉЪЉөբ NarodЁЉЉ P (ЏЉЪ CЉƏЉƏЉЉ NarodհЉՍЉЉ ( aЁ\\nЉЋЪ (...Հ CЉЪЉЪЉЋЋքЉշЪЪƏөЏnЉ.ЉЪЋ PբЉ. , ЁЋЉղՍՍЪ,ЪհЪգЋЉЪ...շհЩЉЋ (ЋЁЉЏգշЋЉЊЋ C.հЉЋЪՄբЋЪЋհЋЋЉ,Љ'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "infer(model, example['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba0c3a-ae58-4296-a3fb-7b0af4e61804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab3afbe-b61c-4161-88b2-aff52a849595",
   "metadata": {},
   "source": [
    "## Add RoPE Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a190e-1053-4d85-8b60-70bcb68a49b9",
   "metadata": {},
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d824084a-c3be-484b-a82a-edd1dd575761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_position_embeddings\": 4096,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": {\n",
       "    \"factor\": 4,\n",
       "    \"rope_type\": \"linear\"\n",
       "  },\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.43.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ropeconfig_linear = AutoConfig.from_pretrained(model_name_or_path, cache_dir=cache_dir, token=ACCESS_TOKEN_READ)\n",
    "ropeconfig_linear.rope_scaling = {\"rope_type\": \"linear\", \"factor\": 4}\n",
    "ropeconfig_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdf1584e-bec6-405d-8918-9334194ce11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafe18b6522541ba8ff942a6924dff58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ropemodel_linear = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    config=ropeconfig_linear,\n",
    "    cache_dir=cache_dir, \n",
    "    device_map='auto',\n",
    "    token=ACCESS_TOKEN_READ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3e3dfe-97b5-49ec-8bdb-8ebf23306c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ropemodel_linear\n",
    "\n",
    "# All rope configs are applied to LlamaRotaryEmbedding()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09a0bc93-cef7-4f77-87f5-a1565041a29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence token length: 12602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.1 s, sys: 6.07 s, total: 35.1 s\n",
      "Wall time: 38.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Researchers have found evidence of microbes living three miles beneath the ocean floor in the deepest part of the ocean, near the Mariana Trench, suggesting that life may be able to survive in the most extreme environments.\\n\\nSummary: Scientists have discovered signs of life in the deepest part of the ocean, which could be three miles below the surface, after finding chemical compounds in rocks from the Mariana Trench, near the Mariana Trench, which could be indicative of microbial life.\\nSummary: New study suggests life may exist three miles deep in the ocean's crust, as signs of organic matter found in rocks near the Mariana Trench, implying life could survive in harsh environments.\\nSummary: Evidence of life found in deepest part of ocean, near Mariana Trench, which could be three miles below surface, suggesting ability to thrive in extreme conditions.\\nSummary: Microbes may live three miles beneath ocean floor, signs of life discovered in Mariana Trench, implying survival in harsh underwater environments.\\nSummary: Researchers find signs of life in deepest part of ocean, could be three miles below surface, suggesting ability to survive in extreme conditions.\\nSummary: Evidence of life found in rocks near Mariana Trench, suggesting microbes may live three miles deep in the ocean.\\nSummary: Study finds signs of life in deepest part of ocean\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s = infer(ropemodel_linear, example['document'])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0899e-fa77-4bf8-90fd-19b35b796214",
   "metadata": {},
   "source": [
    "### dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ea0dfd6-abda-4e81-bc12-42e94b9d0010",
   "metadata": {},
   "outputs": [],
   "source": [
    "ropeconfig_dynamic = AutoConfig.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
    "ropeconfig_dynamic.rope_scaling = {\"rope_type\": \"dynamic\", \"factor\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e315e0fc-934f-4a35-bfa0-81d6b2a3c214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b8d4c6dc3c453b9d04bf1cc32ba13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ropemodel_dynamic = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    config=ropeconfig_dynamic,\n",
    "    cache_dir=cache_dir, \n",
    "    device_map='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "589878bf-2ada-41a2-99fa-40b728079e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence token length: 12602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 s, sys: 5.91 s, total: 21 s\n",
      "Wall time: 26.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Researchers found signs of microbial life in rocks beneath the Mariana Trench, which could be up to 10,0000 meters below the seafloor, suggesting that the deep biosphere may have thrived despite violent phases during Earth' history such as the late heavy bombardment and global mass extinctions.\\n \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "s = infer(ropemodel_dynamic, example['document'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23920e-8d2c-4ef1-b2c5-d9f7d7370dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51bbedd4-3266-4388-90a3-ef3bf562d8eb",
   "metadata": {},
   "source": [
    "### yarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "059650d8-268e-49bf-86aa-c289dc15dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ropeconfig_yarn = AutoConfig.from_pretrained(model_name_or_path, cache_dir=cache_dir, token=ACCESS_TOKEN_READ)\n",
    "ropeconfig_yarn.rope_scaling = {\"rope_type\": \"yarn\", \"factor\": 4} # attention_factor, beta_fast, beta_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3155ed7-56aa-44b9-8259-073ae6397ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20c6d91fef1458a81eb0ef5943fc347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ropemodel_yarn = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    config=ropeconfig_yarn,\n",
    "    cache_dir=cache_dir, \n",
    "    device_map='auto',\n",
    "    token=ACCESS_TOKEN_READ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16aafde2-d019-45a0-b978-946d4ef39ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence token length: 12602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 s, sys: 5.83 s, total: 20.6 s\n",
      "Wall time: 24.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nResearchers have found evidence of microbial life in serpentinite clasts from the Mariana Trench, suggesting that life may exist deeper than previously thought, possibly up to 10,000 meters below the surface.\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "infer(ropemodel_yarn, example['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7df4a-5568-4cd0-896c-bb60222b2ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "520a963b-69ab-4835-be95-f72180ea178b",
   "metadata": {},
   "source": [
    "### longrope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "432e17af-a2ec-4950-9734-ad0a6fa538e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ropeconfig_longrope = AutoConfig.from_pretrained(model_name_or_path, cache_dir=cache_dir, token=ACCESS_TOKEN_READ)\n",
    "ropeconfig_longrope.rope_scaling = {\"rope_type\": \"longrope\", \"factor\": 4, \"short_factor\": 1, \"long_factor\": 4} # attention_factor, short_factor, long_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19db9d33-4741-40f4-82ef-1f2653ca403e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb3d45401fb4885a0ca1b5db72fded3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ropemodel_longrope = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    config=ropeconfig_longrope,\n",
    "    cache_dir=cache_dir, \n",
    "    device_map='auto',\n",
    "    token=ACCESS_TOKEN_READ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a4f8674-12ab-4898-b112-7362aea361ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence token length: 12602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 6.08 s, total: 22.9 s\n",
      "Wall time: 26.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe discovery of complex organic compounds in deep-sea mud samples from the Mariana Trench suggests that microbes may be living as far as 10,0000 meters below the ocean floor, which could extend the known limits of the deep biosphere and provide a new habitat for life to have survived violent events in Earth' history, such as the late bombardment and global mass extinctions.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "infer(ropemodel_longrope, example['document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e80a68-b1b9-4a9b-92eb-306aec4c5197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
